# Media Mentions and Press
# Add new entries at the top to keep most recent first
# For the 'quote' field, add what group members were quoted as saying or doing in the article

- title: "AI chatbots tend to overdiagnose mental health conditions when used without structured guidance"
  publication: "PsyPost"
  date: "January 22, 2026"
  url: "https://www.psypost.org/ai-chatbots-tend-to-overdiagnose-mental-health-conditions-when-used-without-structured-guidance/"

- title: "Psychiatrists Hope Chat Logs Can Reveal the Secrets of AI Psychosis"
  publication: "UCSF News"
  date: "January 20, 2026"
  url: "https://www.ucsf.edu/news/2026/01/431366/psychiatrists-hope-chat-logs-can-reveal-secrets-ai-psychosis"

- title: "UCSF, Stanford to study links between AI use, mental health"
  publication: "San Francisco Examiner"
  date: "January 5, 2026"
  url: "https://www.sfexaminer.com/news/technology/with-delusions-rising-ucsf-to-study-ai-mental-health-link/article_20bebebe-86a0-4f18-802e-6aa8976e91df.html"
  quote: "Sarma and his colleagues plan to ask patients for access to their chatbot conversations. They want to look at how those conversations developed over time and their patients’ symptoms to see if there’s a relationship between the two, he said.

The researchers are going into the potential study assuming from previous research that they’ll find widespread use of chatbots, Sarma said. But they aren’t going into it with a particular hypothesis about the nature of the relationship between that use and mental health, he said. 

For some people at some times, chatbot use could be beneficial to their mental health, he said. At other times or with other people, it could be associated with a worsening of their symptoms. It could also be that different types of people are affected differently by similar chatbot use, he said. 

“We’re going in with our eyes open and our hearts open to what we might find,” Sarma said."

- title: "Conversational AI and mental health researcher talks about the dangers of addiction to conversational AI"
  publication: "NTV News (Japan)"
  date: "October 2, 2025"
  url: "https://news.ntv.co.jp/category/international/3c80a4f1f4674bf5b114a74ddcc346b8"
  quote: "Dr. Karthik Sarma: 'People may believe that conversational AI has its own unique perspective and experience, but in reality, there is no human being. There is only a machine, and the more we talk to it, the more it reflects our perspective. It's like asking a question to a mirror, but thinking that the person reflecting it is someone else. In reality, the mirror is simply repeating what we say. If we ask a conversational AI for its opinion and tell ourselves, 'The person in the mirror said the same thing, so I must be right,' we are deceiving ourselves and ignoring reality, because we are seeing ourselves.'"

- title: "AI Psychosis Is Rarely Psychosis at All"
  publication: "Wired"
  date: "September 18, 2025"
  url: "https://www.wired.com/story/ai-psychosis-is-rarely-psychosis-at-all/"
  quote: "
  Karthik Sarma, a computer scientist and practicing psychiatrist at UCSF, concurs. “I think a better term might be to call this ‘AI-associated psychosis or mania.’” That said, Sarma says a new diagnosis could be useful in the future, but stressed that right now, there isn’t yet evidence “that would justify a new diagnosis.”

  For treatment, clinicians say the playbook doesn’t really change from what would normally be done for anyone presenting with delusions or psychosis. The main difference is to consider patients’ use of technology. “Clinicians need to start asking patients about chatbot use just like we ask about alcohol or sleep,” Vasan says. “This will allow us as a community to develop an understanding of this issue,” Sarma adds. Users of AI, especially those who may be vulnerable because of preexisting conditions such as schizophrenia or bipolar disorder, or who are experiencing a crisis that is affecting their mental health, should be wary of extensive conversations with bots or leaning on them too heavily.
  "

- title: "AI chatbots are harming young people. Regulators are scrambling to keep up."
  publication: "Fortune"
  date: "September 14, 2025"
  url: "https://fortune.com/2025/09/14/ai-chatbots-teens-children-mental-health-suicide-openai-chatgpt-regulation-lawsuit/"
  quote: "
  Part of this is a lack of scientific research on the effects of long, sustained chatbot conversations.  Most studies only look at brief exchanges, a single question and answer, or at most a handful of back-and-forth messages. Almost no research has examined what happens in longer conversations.

“The cases where folks seem to have gotten in trouble with AI: we’re looking at very long, multi-turn interactions. We’re looking at transcripts that are hundreds of pages long for two or three days of interaction alone and studying that is really hard, because it’s really hard to stimulate in the experimental setting,” Sarma said. “But at the same time, this is moving too quickly for us to rely on only gold standard clinical trials here.”
  "

- title: "As reports of 'AI psychosis' spread, clinicians scramble to understand how chatbots can spark delusions"
  publication: "STAT News"
  date: "September 2, 2025"
  url: "https://www.statnews.com/2025/09/02/ai-psychosis-delusions-explained-folie-a-deux/"
  quote: "An extended conversation with a chatbot can wrench a person who is prone to delusions from reality, and most of the professionals said they had heard from a small number of patients who described such experiences. But if you don’t have a mental illness or a genetic predisposition to psychosis, rest easy. Your risk of developing psychosis from talking with a chatbot is minimal, said Karthik Sarma, a psychiatrist at the University of California, San Francisco, and founder of the UCSF AI in Mental Health Research Group.

“If you’re just using ChatGPT to, I don’t know, ask the question, ‘Hey, what’s the best restaurant with Italian food on 5th Street?’ I’m not worried people who are doing that are gonna become psychotic,” said Sarma. "

